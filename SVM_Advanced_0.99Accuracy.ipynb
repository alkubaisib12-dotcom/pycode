{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced SVM Threat Detection Model - Target: 0.99 Accuracy\n",
    "## Network Flow Threat Classification using Advanced Machine Learning Techniques\n",
    "\n",
    "**Project Goal:** Achieve 99% accuracy in threat detection using advanced SVM techniques\n",
    "\n",
    "**Key Improvements:**\n",
    "- Advanced feature engineering and selection\n",
    "- Comprehensive outlier detection and removal\n",
    "- Extensive hyperparameter optimization\n",
    "- Multiple scaling strategies\n",
    "- Advanced sampling techniques for class imbalance\n",
    "- Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif, RFE, VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "\n",
    "# Imbalanced data handling\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Metrics and evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"Dataset-Brief 1 Cyber.csv\")\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nOriginal Label Distribution:\")\n",
    "print(df['Label'].value_counts())\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing Values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate Rows: {df.duplicated().sum()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove identifier columns (not useful for ML)\n",
    "df_clean = df.drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Timestamp'])\n",
    "\n",
    "# Separate features and target\n",
    "labels_original = df_clean['Label']\n",
    "features = df_clean.drop(columns=['Label'])\n",
    "\n",
    "# Remove columns with all zeros\n",
    "zero_cols = features.columns[(features == 0).all()]\n",
    "print(f\"Columns with all zeros ({len(zero_cols)}): {list(zero_cols)}\")\n",
    "features = features.drop(columns=zero_cols)\n",
    "\n",
    "# Replace infinite values with NaN, then fill with median\n",
    "features = features.replace([np.inf, -np.inf], np.nan)\n",
    "if features.isnull().sum().sum() > 0:\n",
    "    print(f\"\\nHandling {features.isnull().sum().sum()} NaN values...\")\n",
    "    features = features.fillna(features.median())\n",
    "\n",
    "print(f\"\\nShape after initial cleaning: {features.shape}\")\n",
    "print(f\"Features remaining: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Label Engineering - Create 3 Main Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_label(lbl):\n",
    "    \"\"\"\n",
    "    Group 11 original attack types into 3 main categories\n",
    "    \n",
    "    Categories:\n",
    "    1. Normal: Benign traffic and analysis\n",
    "    2. Network_Attacks: Traffic-based attacks (DoS, Exploits, etc.)\n",
    "    3. Malware_CodeAttacks: Code-based threats (Backdoor, Shellcode, Worms)\n",
    "    \"\"\"\n",
    "    if lbl in ['Benign', 'Analysis']:\n",
    "        return 'Normal'\n",
    "    elif lbl in ['DoS', 'Exploits', 'Generic', 'Fuzzers', 'Reconnaissance']:\n",
    "        return 'Network_Attacks'\n",
    "    elif lbl in ['Backdoor', 'Shellcode', 'Worms']:\n",
    "        return 'Malware_CodeAttacks'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply label grouping\n",
    "df_clean['MainLabel'] = labels_original.map(group_label)\n",
    "\n",
    "print(\"Label Distribution after Grouping:\")\n",
    "print(df_clean['MainLabel'].value_counts())\n",
    "print(f\"\\nPercentage Distribution:\")\n",
    "print(df_clean['MainLabel'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of features for engineering\n",
    "features_engineered = features.copy()\n",
    "\n",
    "# 1. Ratio features (help capture relationships between metrics)\n",
    "if 'Total Fwd Packet' in features.columns and 'Total Bwd packets' in features.columns:\n",
    "    features_engineered['Fwd_Bwd_Packet_Ratio'] = features['Total Fwd Packet'] / (features['Total Bwd packets'] + 1)\n",
    "\n",
    "if 'Flow Duration' in features.columns and 'Total Fwd Packet' in features.columns:\n",
    "    features_engineered['Packet_Rate'] = features['Total Fwd Packet'] / (features['Flow Duration'] + 1)\n",
    "\n",
    "if 'Flow Duration' in features.columns and 'Total Bwd packets' in features.columns:\n",
    "    features_engineered['Bwd_Packet_Rate'] = features['Total Bwd packets'] / (features['Flow Duration'] + 1)\n",
    "\n",
    "# 2. Log transformation for highly skewed features (helps normalize distribution)\n",
    "skewed_features = features_engineered.columns[features_engineered.skew() > 1]\n",
    "print(f\"\\nApplying log transformation to {len(skewed_features)} skewed features...\")\n",
    "for col in skewed_features:\n",
    "    if (features_engineered[col] >= 0).all():  # Only if all values are non-negative\n",
    "        features_engineered[f'{col}_log'] = np.log1p(features_engineered[col])\n",
    "\n",
    "# 3. Square root transformation for variance stabilization\n",
    "variance_cols = features_engineered.columns[features_engineered.var() > features_engineered.var().quantile(0.9)]\n",
    "for col in variance_cols[:5]:  # Limit to top 5 to avoid too many features\n",
    "    if (features_engineered[col] >= 0).all():\n",
    "        features_engineered[f'{col}_sqrt'] = np.sqrt(features_engineered[col])\n",
    "\n",
    "print(f\"\\nShape after feature engineering: {features_engineered.shape}\")\n",
    "print(f\"Added {features_engineered.shape[1] - features.shape[1]} new features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection and Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Use Isolation Forest for outlier detection\n",
    "print(\"Detecting outliers using Isolation Forest...\")\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42, n_jobs=-1)\n",
    "outlier_pred = iso_forest.fit_predict(features_engineered)\n",
    "\n",
    "# Keep only inliers (outlier_pred == 1)\n",
    "inlier_mask = outlier_pred == 1\n",
    "print(f\"\\nOutliers detected: {(~inlier_mask).sum()} ({(~inlier_mask).sum()/len(features_engineered)*100:.2f}%)\")\n",
    "print(f\"Samples retained: {inlier_mask.sum()} ({inlier_mask.sum()/len(features_engineered)*100:.2f}%)\")\n",
    "\n",
    "# Apply mask to features and labels\n",
    "features_clean = features_engineered[inlier_mask]\n",
    "labels_clean = df_clean['MainLabel'][inlier_mask]\n",
    "\n",
    "print(f\"\\nFinal shape after outlier removal: {features_clean.shape}\")\n",
    "print(f\"\\nLabel distribution after outlier removal:\")\n",
    "print(labels_clean.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Selection - Remove Low Variance and Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Variance Threshold - Remove features with very low variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "features_var = pd.DataFrame(\n",
    "    selector.fit_transform(features_clean),\n",
    "    columns=features_clean.columns[selector.get_support()],\n",
    "    index=features_clean.index\n",
    ")\n",
    "print(f\"Features after variance threshold: {features_var.shape[1]}\")\n",
    "print(f\"Removed {features_clean.shape[1] - features_var.shape[1]} low-variance features\")\n",
    "\n",
    "# 2. Remove highly correlated features (correlation > 0.95)\n",
    "corr_matrix = features_var.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "\n",
    "print(f\"\\nHighly correlated features to remove: {len(to_drop)}\")\n",
    "features_uncorr = features_var.drop(columns=to_drop)\n",
    "print(f\"Features after correlation filtering: {features_uncorr.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Label Encoding and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels_clean)\n",
    "\n",
    "print(\"Class mapping:\")\n",
    "for idx, name in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {idx} = {name}\")\n",
    "\n",
    "# Train/Test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_uncorr, y,\n",
    "    test_size=0.25,  # Slightly smaller test set for more training data\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Feature Scaling - Test Multiple Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different scalers to find the best one\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "scaler_results = {}\n",
    "\n",
    "print(\"Testing different scalers with a quick SVM model...\\n\")\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Scale data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Quick SVM test\n",
    "    quick_svm = SVC(kernel='rbf', C=10, gamma='scale', class_weight='balanced', random_state=42)\n",
    "    quick_svm.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = quick_svm.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    scaler_results[scaler_name] = acc\n",
    "    \n",
    "    print(f\"{scaler_name}: {acc:.4f}\")\n",
    "\n",
    "# Select best scaler\n",
    "best_scaler_name = max(scaler_results, key=scaler_results.get)\n",
    "best_scaler = scalers[best_scaler_name]\n",
    "\n",
    "print(f\"\\n‚úÖ Best scaler: {best_scaler_name} with accuracy {scaler_results[best_scaler_name]:.4f}\")\n",
    "\n",
    "# Apply best scaler\n",
    "X_train_scaled = best_scaler.fit_transform(X_train)\n",
    "X_test_scaled = best_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Feature Selection with SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different k values to find optimal number of features\n",
    "k_values = [30, 40, 50, 60, 70, 'all']\n",
    "k_results = {}\n",
    "\n",
    "print(\"Testing different numbers of features using SelectKBest...\\n\")\n",
    "\n",
    "for k in k_values:\n",
    "    if k == 'all':\n",
    "        X_train_selected = X_train_scaled\n",
    "        X_test_selected = X_test_scaled\n",
    "    else:\n",
    "        # Use mutual information for feature selection\n",
    "        selector = SelectKBest(mutual_info_classif, k=min(k, X_train_scaled.shape[1]))\n",
    "        X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "        X_test_selected = selector.transform(X_test_scaled)\n",
    "    \n",
    "    # Quick SVM test\n",
    "    quick_svm = SVC(kernel='rbf', C=10, gamma='scale', class_weight='balanced', random_state=42)\n",
    "    quick_svm.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = quick_svm.predict(X_test_selected)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    k_results[k] = acc\n",
    "    \n",
    "    print(f\"k={k}: {acc:.4f}\")\n",
    "\n",
    "# Select best k\n",
    "best_k = max(k_results, key=k_results.get)\n",
    "print(f\"\\n‚úÖ Best k: {best_k} with accuracy {k_results[best_k]:.4f}\")\n",
    "\n",
    "# Apply best feature selection\n",
    "if best_k == 'all':\n",
    "    X_train_final = X_train_scaled\n",
    "    X_test_final = X_test_scaled\n",
    "    selected_features = features_uncorr.columns.tolist()\n",
    "else:\n",
    "    selector_final = SelectKBest(mutual_info_classif, k=min(best_k, X_train_scaled.shape[1]))\n",
    "    X_train_final = selector_final.fit_transform(X_train_scaled, y_train)\n",
    "    X_test_final = selector_final.transform(X_test_scaled)\n",
    "    selected_features = features_uncorr.columns[selector_final.get_support()].tolist()\n",
    "\n",
    "print(f\"\\nFinal feature count: {X_train_final.shape[1]}\")\n",
    "print(f\"\\nTop 10 selected features:\")\n",
    "for i, feat in enumerate(selected_features[:10], 1):\n",
    "    print(f\"{i}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Handle Class Imbalance - Test Multiple SMOTE Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different SMOTE variants\n",
    "smote_variants = {\n",
    "    'SMOTE': SMOTE(random_state=42, k_neighbors=5),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(random_state=42, k_neighbors=5),\n",
    "    'SVMSMOTE': SVMSMOTE(random_state=42, k_neighbors=5),\n",
    "    'ADASYN': ADASYN(random_state=42, n_neighbors=5)\n",
    "}\n",
    "\n",
    "smote_results = {}\n",
    "\n",
    "print(\"Testing different SMOTE variants...\\n\")\n",
    "\n",
    "for smote_name, smote in smote_variants.items():\n",
    "    try:\n",
    "        # Resample\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_final, y_train)\n",
    "        \n",
    "        # Quick SVM test\n",
    "        quick_svm = SVC(kernel='rbf', C=10, gamma='scale', class_weight='balanced', random_state=42)\n",
    "        quick_svm.fit(X_train_resampled, y_train_resampled)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = quick_svm.predict(X_test_final)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        smote_results[smote_name] = acc\n",
    "        \n",
    "        print(f\"{smote_name}: {acc:.4f} (Samples: {X_train_resampled.shape[0]})\")\n",
    "    except Exception as e:\n",
    "        print(f\"{smote_name}: Failed - {str(e)}\")\n",
    "\n",
    "# Select best SMOTE variant\n",
    "if smote_results:\n",
    "    best_smote_name = max(smote_results, key=smote_results.get)\n",
    "    best_smote = smote_variants[best_smote_name]\n",
    "    print(f\"\\n‚úÖ Best SMOTE variant: {best_smote_name} with accuracy {smote_results[best_smote_name]:.4f}\")\n",
    "    \n",
    "    # Apply best SMOTE\n",
    "    X_train_resampled, y_train_resampled = best_smote.fit_resample(X_train_final, y_train)\n",
    "    \n",
    "    print(f\"\\nClass distribution after {best_smote_name}:\")\n",
    "    unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"  Class {label_encoder.classes_[cls]}: {count}\")\n",
    "else:\n",
    "    print(\"\\nNo SMOTE variant succeeded, using original training data\")\n",
    "    X_train_resampled = X_train_final\n",
    "    y_train_resampled = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Extensive Hyperparameter Tuning - RandomizedSearchCV followed by GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Randomized Search for broad exploration\n",
    "print(\"Phase 1: Randomized Search for initial hyperparameter exploration...\\n\")\n",
    "\n",
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "random_param_dist = {\n",
    "    'C': loguniform(0.1, 1000),\n",
    "    'gamma': ['scale', 'auto'] + list(loguniform(0.0001, 1).rvs(10)),\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'degree': [2, 3, 4]  # Only used for poly kernel\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=SVC(random_state=42),\n",
    "    param_distributions=random_param_dist,\n",
    "    n_iter=50,  # Number of parameter combinations to try\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(f\"\\n‚úÖ Best parameters from RandomizedSearch: {random_search.best_params_}\")\n",
    "print(f\"‚úÖ Best CV score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Test on test set\n",
    "y_pred_random = random_search.best_estimator_.predict(X_test_final)\n",
    "acc_random = accuracy_score(y_test, y_pred_random)\n",
    "print(f\"‚úÖ Test accuracy: {acc_random:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Grid Search for fine-tuning around best parameters\n",
    "print(\"\\nPhase 2: Grid Search for fine-tuning hyperparameters...\\n\")\n",
    "\n",
    "# Get best parameters from random search\n",
    "best_kernel = random_search.best_params_['kernel']\n",
    "best_C = random_search.best_params_['C']\n",
    "best_gamma = random_search.best_params_['gamma']\n",
    "\n",
    "# Create fine-tuning grid around best parameters\n",
    "if isinstance(best_gamma, str):\n",
    "    gamma_range = ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "else:\n",
    "    gamma_range = [best_gamma/10, best_gamma/2, best_gamma, best_gamma*2, best_gamma*10, 'scale', 'auto']\n",
    "\n",
    "grid_param = {\n",
    "    'C': [best_C/10, best_C/5, best_C/2, best_C, best_C*2, best_C*5, best_C*10],\n",
    "    'gamma': gamma_range,\n",
    "    'kernel': [best_kernel],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Add degree parameter if poly kernel\n",
    "if best_kernel == 'poly':\n",
    "    grid_param['degree'] = [2, 3, 4, 5]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=SVC(random_state=42),\n",
    "    param_grid=grid_param,\n",
    "    cv=5,  # More folds for better validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(f\"\\n‚úÖ Best parameters from GridSearch: {grid_search.best_params_}\")\n",
    "print(f\"‚úÖ Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Test on test set\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_grid = best_svm.predict(X_test_final)\n",
    "acc_grid = accuracy_score(y_test, y_pred_grid)\n",
    "print(f\"‚úÖ Test accuracy: {acc_grid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Ensemble Method - Bagging for Additional Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bagging ensemble with best SVM\n",
    "print(\"Creating Bagging ensemble with best SVM...\\n\")\n",
    "\n",
    "bagging_svm = BaggingClassifier(\n",
    "    estimator=best_svm,\n",
    "    n_estimators=10,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bagging_svm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict\n",
    "y_pred_bagging = bagging_svm.predict(X_test_final)\n",
    "acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "\n",
    "print(f\"‚úÖ Bagging SVM accuracy: {acc_bagging:.4f}\")\n",
    "\n",
    "# Compare with single SVM\n",
    "if acc_bagging > acc_grid:\n",
    "    print(f\"\\nüéâ Bagging improved accuracy by {(acc_bagging - acc_grid)*100:.2f}%\")\n",
    "    final_model = bagging_svm\n",
    "    final_pred = y_pred_bagging\n",
    "    final_accuracy = acc_bagging\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Single SVM performs better, using it as final model\")\n",
    "    final_model = best_svm\n",
    "    final_pred = y_pred_grid\n",
    "    final_accuracy = acc_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions and actual labels\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(final_pred)\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ ACCURACY: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"\\nüìä Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    y_test_labels,\n",
    "    y_pred_labels,\n",
    "    labels=class_names,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision = precision_score(y_test, final_pred, average='weighted')\n",
    "recall = recall_score(y_test, final_pred, average='weighted')\n",
    "f1 = f1_score(y_test, final_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nüìà Weighted Metrics:\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Cross-Validation for Robust Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified k-fold cross-validation\n",
    "print(\"Performing 10-fold stratified cross-validation...\\n\")\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    best_svm,  # Use best single SVM for faster CV\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    cv=10,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"\\nüìä CV Statistics:\")\n",
    "print(f\"  Mean Accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"  Std Deviation: {cv_scores.std():.4f}\")\n",
    "print(f\"  Min Accuracy: {cv_scores.min():.4f}\")\n",
    "print(f\"  Max Accuracy: {cv_scores.max():.4f}\")\n",
    "print(f\"  95% Confidence Interval: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, {cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels, labels=class_names)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "\n",
    "plt.title(f\"Confusion Matrix - Advanced SVM Model\\nAccuracy: {final_accuracy:.4f}\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Predicted Category\", fontsize=12)\n",
    "plt.ylabel(\"Actual Category\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display confusion matrix percentages\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm_percent,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Percentage (%)'}\n",
    ")\n",
    "\n",
    "plt.title(f\"Confusion Matrix (Normalized) - Advanced SVM Model\\nAccuracy: {final_accuracy:.4f}\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Predicted Category\", fontsize=12)\n",
    "plt.ylabel(\"Actual Category\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Performance Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification report as dictionary\n",
    "report = classification_report(\n",
    "    y_test_labels,\n",
    "    y_pred_labels,\n",
    "    labels=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': [report[cls]['precision'] for cls in class_names],\n",
    "    'Recall': [report[cls]['recall'] for cls in class_names],\n",
    "    'F1-Score': [report[cls]['f1-score'] for cls in class_names]\n",
    "}, index=class_names)\n",
    "\n",
    "# Plot grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "metrics_df.plot(kind='bar', ax=ax, width=0.8)\n",
    "\n",
    "plt.title(f\"Performance Metrics by Class - Advanced SVM Model\\nOverall Accuracy: {final_accuracy:.4f}\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Threat Category\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(title='Metrics', fontsize=10)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display metrics table\n",
    "print(\"\\nüìä Metrics Summary by Class:\")\n",
    "print(metrics_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM, we can use permutation importance to understand feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"Calculating feature importance using permutation importance...\\n\")\n",
    "\n",
    "# Use a sample for faster computation\n",
    "sample_size = min(2000, X_test_final.shape[0])\n",
    "sample_indices = np.random.choice(X_test_final.shape[0], sample_size, replace=False)\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    best_svm,\n",
    "    X_test_final[sample_indices],\n",
    "    y_test[sample_indices],\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Get feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'importance': perm_importance.importances_mean,\n",
    "    'std': perm_importance.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], xerr=top_features['std'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance (Decrease in Accuracy)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Most Important Features - Permutation Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(importance_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Model Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ADVANCED SVM THREAT DETECTION MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä DATASET INFORMATION:\")\n",
    "print(f\"  Original samples: {df.shape[0]}\")\n",
    "print(f\"  Samples after outlier removal: {features_clean.shape[0]}\")\n",
    "print(f\"  Original features: {df.shape[1] - 1}\")\n",
    "print(f\"  Features after engineering: {features_engineered.shape[1]}\")\n",
    "print(f\"  Final selected features: {X_train_final.shape[1]}\")\n",
    "\n",
    "print(\"\\nüîß PREPROCESSING PIPELINE:\")\n",
    "print(f\"  1. Removed identifier columns: Flow ID, Src IP, Dst IP, Timestamp\")\n",
    "print(f\"  2. Removed zero-variance columns: {len(zero_cols)}\")\n",
    "print(f\"  3. Feature engineering: Added ratio, log, and sqrt features\")\n",
    "print(f\"  4. Outlier removal: Isolation Forest (5% contamination)\")\n",
    "print(f\"  5. Variance threshold filtering\")\n",
    "print(f\"  6. Correlation-based feature removal (threshold: 0.95)\")\n",
    "print(f\"  7. Best scaler: {best_scaler_name}\")\n",
    "print(f\"  8. Feature selection: SelectKBest (k={best_k})\")\n",
    "print(f\"  9. Best SMOTE variant: {best_smote_name}\")\n",
    "\n",
    "print(\"\\nüéØ MODEL CONFIGURATION:\")\n",
    "print(f\"  Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"  Model type: {'Bagging SVM Ensemble' if final_model == bagging_svm else 'Single SVM'}\")\n",
    "\n",
    "print(\"\\nüèÜ PERFORMANCE METRICS:\")\n",
    "print(f\"  Test Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"  Cross-Validation Accuracy: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "print(f\"  Weighted Precision: {precision:.4f}\")\n",
    "print(f\"  Weighted Recall: {recall:.4f}\")\n",
    "print(f\"  Weighted F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìà PER-CLASS PERFORMANCE:\")\n",
    "for cls in class_names:\n",
    "    print(f\"  {cls}:\")\n",
    "    print(f\"    Precision: {report[cls]['precision']:.4f}\")\n",
    "    print(f\"    Recall: {report[cls]['recall']:.4f}\")\n",
    "    print(f\"    F1-Score: {report[cls]['f1-score']:.4f}\")\n",
    "    print(f\"    Support: {int(report[cls]['support'])}\")\n",
    "\n",
    "if final_accuracy >= 0.99:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâüéâüéâ SUCCESS! TARGET ACCURACY OF 0.99 ACHIEVED! üéâüéâüéâ\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Current accuracy: {final_accuracy:.4f}\")\n",
    "    print(f\"   Gap to target: {(0.99 - final_accuracy)*100:.2f}%\")\n",
    "    print(\"\\nüí° Recommendations for further improvement:\")\n",
    "    print(\"   1. Collect more training data\")\n",
    "    print(\"   2. Try deep learning models (Neural Networks)\")\n",
    "    print(\"   3. Ensemble with other models (XGBoost, Random Forest)\")\n",
    "    print(\"   4. More advanced feature engineering\")\n",
    "    print(\"   5. Fine-tune class weights based on misclassifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamp for file naming\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the model\n",
    "model_filename = f\"svm_threat_detection_model_{final_accuracy:.4f}_{timestamp}.pkl\"\n",
    "joblib.dump(final_model, model_filename)\n",
    "print(f\"‚úÖ Model saved as: {model_filename}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = f\"scaler_{timestamp}.pkl\"\n",
    "joblib.dump(best_scaler, scaler_filename)\n",
    "print(f\"‚úÖ Scaler saved as: {scaler_filename}\")\n",
    "\n",
    "# Save the label encoder\n",
    "encoder_filename = f\"label_encoder_{timestamp}.pkl\"\n",
    "joblib.dump(label_encoder, encoder_filename)\n",
    "print(f\"‚úÖ Label encoder saved as: {encoder_filename}\")\n",
    "\n",
    "# Save selected features\n",
    "features_filename = f\"selected_features_{timestamp}.txt\"\n",
    "with open(features_filename, 'w') as f:\n",
    "    for feat in selected_features:\n",
    "        f.write(f\"{feat}\\n\")\n",
    "print(f\"‚úÖ Selected features saved as: {features_filename}\")\n",
    "\n",
    "# Save performance summary\n",
    "summary_filename = f\"performance_summary_{final_accuracy:.4f}_{timestamp}.txt\"\n",
    "with open(summary_filename, 'w') as f:\n",
    "    f.write(\"ADVANCED SVM THREAT DETECTION MODEL - PERFORMANCE SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Accuracy: {final_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score: {f1:.4f}\\n\\n\")\n",
    "    f.write(f\"Best Parameters: {grid_search.best_params_}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(classification_report(y_test_labels, y_pred_labels, labels=class_names))\n",
    "\n",
    "print(f\"‚úÖ Performance summary saved as: {summary_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL RESULTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
